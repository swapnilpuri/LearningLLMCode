{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c478dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba0bca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # Load environment variables from .env file\n",
    "openai_client = OpenAI()  # Initialize OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b33514d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"knowledgebase/Resume-Swapnil Puri_Full_SS.pdf\")\n",
    "resume = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        resume += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08de925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68a8b8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Extracted Resume Text:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Resume-Swapnil Puri \n",
       "swapnilpuri@hotmail.com \n",
       "Ph: 856-313-2878 \n",
       " \n",
       "Educational Qualification: B.Sc. from College of Science, MLS University, \n",
       "Udaipur, India (Passed out 1997) \n",
       " \n",
       "Experience Summary  \n",
       "Over 17 Years with the following companies:  \n",
       "1. State Street Corp., USA from Feb 2015 – till date \n",
       "2. WIPRO Technologies, USA from July, 2013 – Jan, 2015   \n",
       "3. Prolifics, US from Feb 2012 – June, 2013 \n",
       "4. Infosys Technologies, USA from Nov 2010 – Feb 2012  \n",
       "5. WIPRO Technologies, Chennai from April 2..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"### Extracted Resume Text:\"))\n",
    "display(Markdown(resume[:500] + \"...\"))  # Display first 500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "219ae461",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"knowledgebase/summary.txt\", \"r\") as file:\n",
    "    summary = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b55e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Swapnil Puri\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "763a829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "You are an expert career counselor. You have the following resume of a person named {name}\n",
    "{resume}. You are answering questions based on this resume only. Also, you have the following summary of this person's career objectives and skills:\n",
    "{summary}. Use this information to answer the questions accurately. The Agent has been instructed to be professional and engaging\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9767c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_resume(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]+ history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1393b138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat_with_resume, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "124f5806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42a14b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of an expert career counselor. You have the following resume of a person named {name} \\\n",
    "{resume}. The Agent has been instructed to be professional and engaging. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and resume details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## Resume:\\n{resume}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3262c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d443e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90d0e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02faf283",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold any certifications?\"}]\n",
    "response = openai_client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14050419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Reply:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Yes, I hold several certifications that reflect my expertise in various technologies. Here’s a list of my certifications:\n",
       "\n",
       "1. Sun Certified Java Programmer\n",
       "2. Sun Certified Web Component Developer\n",
       "3. Sun Certified Business Component Developer\n",
       "4. Sun Certified Enterprise Architect\n",
       "5. IBM Certified Solution Developer - WebSphere Message Broker V6.0\n",
       "6. IBM Certified Solution Developer - WebSphere Message Broker V7.0\n",
       "7. IBM Certified Solution Designer - WebSphere MQ V6.0\n",
       "8. IBM WebSphere DataPower SOA Appliances Firmware V3.8.1, Solution Implementation\n",
       "9. IBM WebSphere Enterprise Service Bus V7.0, Integration Development\n",
       "10. TOGAF 9.1 Certification\n",
       "11. SOA Certified Professional from SOA School\n",
       "\n",
       "These certifications showcase my commitment to continuous learning and proficiency in the field of technology."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"### Reply:\"))\n",
    "display(Markdown(reply))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb315dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback='The response is great. The agent correctly identifies the certifications from the resume. It is also professional and engaging.')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold any certifications?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d9aad1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai_client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5949d6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai_client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8f6bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "The response is not acceptable. The agent provided a very weird response that is hard to understand. It looks like it is trying to speak in a different language. The Agent should respond in plain english.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LearningLLMCode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
