{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34948e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90868da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "# Loads variables from .env file and overwrites any existing environment variables with the same name\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e988aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a5b932c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a technical question for interview about LLMs.Answer only with the question and no explanations.'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llmrequest = \"Please come up with a technical question for interview about LLMs.\"\n",
    "llmrequest += \"Answer only with the question and no explanations.\"\n",
    "messages = [{\"role\": \"user\", \"content\": llmrequest}]\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99bd27c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**OpenAI GPT-4o-mini Question:** What are the key differences between fine-tuning a large language model (LLM) and using prompt engineering, and in what scenarios would you prefer one method over the other?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "openai_client = OpenAI()\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "llmquestion = response.choices[0].message.content\n",
    "display(Markdown(f\"**OpenAI GPT-4o-mini Question:** {llmquestion}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd48506c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-CSb3ZagQrXpWhRfHjWaVGbeBwC3TG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='What are the key differences between fine-tuning a large language model (LLM) and using prompt engineering, and in what scenarios would you prefer one method over the other?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1760931665, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=35, prompt_tokens=30, total_tokens=65, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06915d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-CSb3aEpfol9oumxzMfqQIS8fsupVQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Fine-tuning a large language model (LLM) and prompt engineering are two distinct approaches for tailoring a model's outputs to meet specific needs. Here's an overview of their key differences, along with scenarios where one might be preferable over the other.\\n\\n### Key Differences\\n\\n1. **Methodology**:\\n   - **Fine-tuning**: This involves training the existing model further on a specific dataset that is more representative of the task or domain at hand. This process modifies the model's weights based on the new data, allowing it to learn domain-specific language patterns, facts, and styles.\\n   - **Prompt Engineering**: This involves crafting prompts or questions to guide the model’s responses. It leverages the model’s pre-existing capabilities without changing the model itself. Techniques include using specific wording, context, examples, and constraints to elicit desired behavior from the model.\\n\\n2. **Complexity**:\\n   - **Fine-tuning**: Typically requires technical expertise in machine learning, access to computational resources, and a sufficient amount of domain-specific training data.\\n   - **Prompt Engineering**: Generally more straightforward and accessible; can often be done with no special training or resources beyond the ability to interact with the model.\\n\\n3. **Resource Requirements**:\\n   - **Fine-tuning**: Requires substantial computational power, time, and, often, a clear understanding of model training. This may involve costs related to cloud computing or hardware usage.\\n   - **Prompt Engineering**: Is usually less resource-intensive and immediate, as it works with the model in its existing state and requires no additional training cycle.\\n\\n4. **Flexibility**:\\n   - **Fine-tuning**: Once fine-tuned, a model may become highly specific to the new data it was trained on, which can limit its flexibility in general-purpose tasks.\\n   - **Prompt Engineering**: Allows for adaptation to multiple scenarios without affecting the underlying model, making it easier to switch focus across different tasks.\\n\\n5. **Data Requirements**:\\n   - **Fine-tuning**: Needs substantial amounts of labeled training data, and the quality and relevance of this data significantly impact the model's performance.\\n   - **Prompt Engineering**: Does not require additional data but benefits from understanding how to structure prompts effectively. \\n\\n### Scenarios for Preference\\n\\n- **Choose Fine-tuning When**:\\n  - You have a large amount of domain-specific data available for training.\\n  - You need high accuracy and specific performance on a narrow task.\\n  - You want to create a proprietary version of the model for commercial use.\\n  - You expect to have constant, significant changes in the domain that require continuous updates.\\n\\n- **Choose Prompt Engineering When**:\\n  - You need quick, flexible responses without the need for extensive retraining.\\n  - You have limited access to domain-specific data or computational resources.\\n  - You want to experiment quickly across multiple tasks or domains.\\n  - You're interacting with the model in real-time and need adaptability without long preparation times.\\n\\nBoth methods can be used in conjunction. For instance, initial results may be achieved through prompt engineering, and if those results show promise, fine-tuning could then be considered for deeper optimization over time.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1760931666, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=643, prompt_tokens=42, total_tokens=685, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": llmquestion}]\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50c3a86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning a large language model (LLM) and prompt engineering are two distinct approaches for tailoring a model's outputs to meet specific needs. Here's an overview of their key differences, along with scenarios where one might be preferable over the other.\n",
      "\n",
      "### Key Differences\n",
      "\n",
      "1. **Methodology**:\n",
      "   - **Fine-tuning**: This involves training the existing model further on a specific dataset that is more representative of the task or domain at hand. This process modifies the model's weights based on the new data, allowing it to learn domain-specific language patterns, facts, and styles.\n",
      "   - **Prompt Engineering**: This involves crafting prompts or questions to guide the model’s responses. It leverages the model’s pre-existing capabilities without changing the model itself. Techniques include using specific wording, context, examples, and constraints to elicit desired behavior from the model.\n",
      "\n",
      "2. **Complexity**:\n",
      "   - **Fine-tuning**: Typically requires technical expertise in machine learning, access to computational resources, and a sufficient amount of domain-specific training data.\n",
      "   - **Prompt Engineering**: Generally more straightforward and accessible; can often be done with no special training or resources beyond the ability to interact with the model.\n",
      "\n",
      "3. **Resource Requirements**:\n",
      "   - **Fine-tuning**: Requires substantial computational power, time, and, often, a clear understanding of model training. This may involve costs related to cloud computing or hardware usage.\n",
      "   - **Prompt Engineering**: Is usually less resource-intensive and immediate, as it works with the model in its existing state and requires no additional training cycle.\n",
      "\n",
      "4. **Flexibility**:\n",
      "   - **Fine-tuning**: Once fine-tuned, a model may become highly specific to the new data it was trained on, which can limit its flexibility in general-purpose tasks.\n",
      "   - **Prompt Engineering**: Allows for adaptation to multiple scenarios without affecting the underlying model, making it easier to switch focus across different tasks.\n",
      "\n",
      "5. **Data Requirements**:\n",
      "   - **Fine-tuning**: Needs substantial amounts of labeled training data, and the quality and relevance of this data significantly impact the model's performance.\n",
      "   - **Prompt Engineering**: Does not require additional data but benefits from understanding how to structure prompts effectively. \n",
      "\n",
      "### Scenarios for Preference\n",
      "\n",
      "- **Choose Fine-tuning When**:\n",
      "  - You have a large amount of domain-specific data available for training.\n",
      "  - You need high accuracy and specific performance on a narrow task.\n",
      "  - You want to create a proprietary version of the model for commercial use.\n",
      "  - You expect to have constant, significant changes in the domain that require continuous updates.\n",
      "\n",
      "- **Choose Prompt Engineering When**:\n",
      "  - You need quick, flexible responses without the need for extensive retraining.\n",
      "  - You have limited access to domain-specific data or computational resources.\n",
      "  - You want to experiment quickly across multiple tasks or domains.\n",
      "  - You're interacting with the model in real-time and need adaptability without long preparation times.\n",
      "\n",
      "Both methods can be used in conjunction. For instance, initial results may be achieved through prompt engineering, and if those results show promise, fine-tuning could then be considered for deeper optimization over time.\n"
     ]
    }
   ],
   "source": [
    "answerforq = response.choices[0].message.content\n",
    "print(answerforq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e72a4600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Fine-tuning a large language model (LLM) and prompt engineering are two distinct approaches for tailoring a model's outputs to meet specific needs. Here's an overview of their key differences, along with scenarios where one might be preferable over the other.\n",
       "\n",
       "### Key Differences\n",
       "\n",
       "1. **Methodology**:\n",
       "   - **Fine-tuning**: This involves training the existing model further on a specific dataset that is more representative of the task or domain at hand. This process modifies the model's weights based on the new data, allowing it to learn domain-specific language patterns, facts, and styles.\n",
       "   - **Prompt Engineering**: This involves crafting prompts or questions to guide the model’s responses. It leverages the model’s pre-existing capabilities without changing the model itself. Techniques include using specific wording, context, examples, and constraints to elicit desired behavior from the model.\n",
       "\n",
       "2. **Complexity**:\n",
       "   - **Fine-tuning**: Typically requires technical expertise in machine learning, access to computational resources, and a sufficient amount of domain-specific training data.\n",
       "   - **Prompt Engineering**: Generally more straightforward and accessible; can often be done with no special training or resources beyond the ability to interact with the model.\n",
       "\n",
       "3. **Resource Requirements**:\n",
       "   - **Fine-tuning**: Requires substantial computational power, time, and, often, a clear understanding of model training. This may involve costs related to cloud computing or hardware usage.\n",
       "   - **Prompt Engineering**: Is usually less resource-intensive and immediate, as it works with the model in its existing state and requires no additional training cycle.\n",
       "\n",
       "4. **Flexibility**:\n",
       "   - **Fine-tuning**: Once fine-tuned, a model may become highly specific to the new data it was trained on, which can limit its flexibility in general-purpose tasks.\n",
       "   - **Prompt Engineering**: Allows for adaptation to multiple scenarios without affecting the underlying model, making it easier to switch focus across different tasks.\n",
       "\n",
       "5. **Data Requirements**:\n",
       "   - **Fine-tuning**: Needs substantial amounts of labeled training data, and the quality and relevance of this data significantly impact the model's performance.\n",
       "   - **Prompt Engineering**: Does not require additional data but benefits from understanding how to structure prompts effectively. \n",
       "\n",
       "### Scenarios for Preference\n",
       "\n",
       "- **Choose Fine-tuning When**:\n",
       "  - You have a large amount of domain-specific data available for training.\n",
       "  - You need high accuracy and specific performance on a narrow task.\n",
       "  - You want to create a proprietary version of the model for commercial use.\n",
       "  - You expect to have constant, significant changes in the domain that require continuous updates.\n",
       "\n",
       "- **Choose Prompt Engineering When**:\n",
       "  - You need quick, flexible responses without the need for extensive retraining.\n",
       "  - You have limited access to domain-specific data or computational resources.\n",
       "  - You want to experiment quickly across multiple tasks or domains.\n",
       "  - You're interacting with the model in real-time and need adaptability without long preparation times.\n",
       "\n",
       "Both methods can be used in conjunction. For instance, initial results may be achieved through prompt engineering, and if those results show promise, fine-tuning could then be considered for deeper optimization over time."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(answerforq))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LearningLLMCode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
